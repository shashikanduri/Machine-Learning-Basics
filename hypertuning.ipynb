{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team: &emsp;&emsp; Sasi Kanduri &emsp;&emsp; Vikas Mishra &emsp;&emsp; Ashish Kotian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting .mat files to jpg and image arrays\n",
    "##### The dataset we chose is from the follwoing link which has images in .mat files. We have to take the image arrays out of the .mat constructs and pre-process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import SimpleITK as sitk\n",
    "# List of directories to process\n",
    "directories = [\n",
    "    'brainTumorDataPublic_1-766',\n",
    "    'brainTumorDataPublic_767-1532',\n",
    "    'brainTumorDataPublic_1533-2298',\n",
    "    'brainTumorDataPublic_2299-3064'\n",
    "]\n",
    "\n",
    "y_labels = []\n",
    "filename_column = []\n",
    "\n",
    "image_arrays = []\n",
    "image_classes = []\n",
    "\n",
    "\n",
    "# Set the paths for the Mat and Jpg folders\n",
    "mat_folder = f'./all_files'\n",
    "jpg_folder = f'./Jpg_images'\n",
    "\n",
    "# Create the Jpg folder if it doesn't exist\n",
    "if not os.path.exists(jpg_folder):\n",
    "    os.makedirs(jpg_folder)\n",
    "\n",
    "# Iterate through files in the Mat folder\n",
    "for filename in os.listdir(mat_folder):\n",
    "    # Construct the full file paths\n",
    "    mat_filepath = os.path.join(mat_folder, filename)\n",
    "    jpg_filepath = os.path.join(jpg_folder, filename.split(\".\")[0] + '.jpg')\n",
    "\n",
    "    if filename.endswith('.mat'):\n",
    "        # Check if the Mat file path is valid\n",
    "        if os.path.exists(mat_filepath) and os.path.isfile(mat_filepath):\n",
    "            try:\n",
    "                # Open the mat file\n",
    "                with h5py.File(mat_filepath, 'r+') as f:\n",
    "\n",
    "                    cjdata = f['cjdata']\n",
    "                    image = np.array(cjdata.get('image')).astype(np.float64)\n",
    "                    label = cjdata.get('label')[0, 0]\n",
    "\n",
    "                    if image.shape[0] == 512:\n",
    "\n",
    "                        y_labels.append(label - 1)\n",
    "                        filename_column.append(filename.split(\".\")[0])\n",
    "\n",
    "                        # Perform image processing\n",
    "                        hi = np.max(image)\n",
    "                        lo = np.min(image)\n",
    "                        image = (((image - lo) / (hi - lo))\n",
    "                                 * 255).astype(np.uint8)\n",
    "\n",
    "                        image = cv2.resize(\n",
    "                            image, (128, 128), interpolation=cv2.INTER_AREA)\n",
    "                        image_arrays.append(image)\n",
    "                        image_classes.append(label - 1)\n",
    "\n",
    "                        # cv2.imwrite(jpg_filepath, image)\n",
    "                        # t1_image = sitk.GetImageFromArray(image)\n",
    "                        # sitk.WriteImage(t1_image, jpg_filepath)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"Invalid Mat file path: {mat_filepath}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Skipping non-HDF5 file: {filename}\")\n",
    "\n",
    "df = pd.DataFrame({'filename': filename_column, 'label': y_labels})\n",
    "df.to_csv('final_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.utils import plot_model, image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D, Rescaling\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_df.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='filename', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename      int64\n",
       "label       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].astype('int32')\n",
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_labels = df['label'].to_numpy().tolist()\n",
    "y_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arrays = np.array(image_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arrays = image_arrays.reshape(image_arrays.shape[0], 128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]], dtype=uint8)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_classes_encoded = tf.keras.utils.to_categorical(image_classes, 3, \"float32\")\n",
    "image_classes_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3049, 128, 128, 1)\n",
      "(3049, 3)\n"
     ]
    }
   ],
   "source": [
    "print(image_arrays.shape)\n",
    "print(image_classes_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(image_arrays, image_classes_encoded, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2439, 128, 128, 1)\n",
      "(610, 128, 128, 1)\n",
      "(2439, 3)\n",
      "(610, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Rescaling, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(128, 128, 1)))\n",
    "    model.add(Rescaling(1./255))  # scale pixels\n",
    "\n",
    "    # Define the number of CNN layers as a hyperparameter\n",
    "    num_cnn_layers = hp.Int('num_cnn_layers', min_value=1, max_value=10, step=1)\n",
    "\n",
    "    for i in range(num_cnn_layers):\n",
    "        model.add(Conv2D(64, kernel_size=(2, 2), padding='same', strides=1, activation=hp.Choice('activation', values=['relu', 'tanh'])))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(hp.Choice('units', [8, 16, 32]), activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,\n",
    "    directory='my_dir',\n",
    "    project_name='my_project')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"array_model.hdf5\", verbose=2, save_best_only=True, monitor='val_loss')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 08m 44s]\n",
      "val_loss: 0.23218651115894318\n",
      "\n",
      "Best val_loss So Far: 0.23218651115894318\n",
      "Total elapsed time: 00h 45m 15s\n",
      "{'num_cnn_layers': 3, 'activation': 'relu', 'units': 8, 'learning_rate': 0.0007539027884617362}\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs=20, validation_data=(x_test, y_test), callbacks=[monitor, checkpointer], batch_size=32)\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "# tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val))\n",
    "\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test), callbacks=[monitor, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.9539 - accuracy: 0.5953\n",
      "Epoch 1: val_loss improved from inf to 0.88772, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 31s 396ms/step - loss: 0.9539 - accuracy: 0.5953 - val_loss: 0.8877 - val_accuracy: 0.7131\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.8507 - accuracy: 0.7048\n",
      "Epoch 2: val_loss improved from 0.88772 to 0.82882, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 392ms/step - loss: 0.8507 - accuracy: 0.7048 - val_loss: 0.8288 - val_accuracy: 0.6869\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.8121 - accuracy: 0.7175\n",
      "Epoch 3: val_loss improved from 0.82882 to 0.79916, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 394ms/step - loss: 0.8121 - accuracy: 0.7175 - val_loss: 0.7992 - val_accuracy: 0.7000\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.7733 - accuracy: 0.7302\n",
      "Epoch 4: val_loss improved from 0.79916 to 0.75883, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 396ms/step - loss: 0.7733 - accuracy: 0.7302 - val_loss: 0.7588 - val_accuracy: 0.7492\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.7459 - accuracy: 0.7335\n",
      "Epoch 5: val_loss improved from 0.75883 to 0.75729, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 391ms/step - loss: 0.7459 - accuracy: 0.7335 - val_loss: 0.7573 - val_accuracy: 0.7443\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.7170 - accuracy: 0.7437\n",
      "Epoch 6: val_loss improved from 0.75729 to 0.69621, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 31s 396ms/step - loss: 0.7170 - accuracy: 0.7437 - val_loss: 0.6962 - val_accuracy: 0.7672\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.7712\n",
      "Epoch 7: val_loss improved from 0.69621 to 0.66271, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 393ms/step - loss: 0.6787 - accuracy: 0.7712 - val_loss: 0.6627 - val_accuracy: 0.7852\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.6441 - accuracy: 0.7823\n",
      "Epoch 8: val_loss improved from 0.66271 to 0.61923, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 396ms/step - loss: 0.6441 - accuracy: 0.7823 - val_loss: 0.6192 - val_accuracy: 0.7984\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.7880\n",
      "Epoch 9: val_loss improved from 0.61923 to 0.58396, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 394ms/step - loss: 0.6047 - accuracy: 0.7880 - val_loss: 0.5840 - val_accuracy: 0.7951\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.5521 - accuracy: 0.7880\n",
      "Epoch 10: val_loss improved from 0.58396 to 0.47066, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 395ms/step - loss: 0.5521 - accuracy: 0.7880 - val_loss: 0.4707 - val_accuracy: 0.7820\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8048\n",
      "Epoch 11: val_loss did not improve from 0.47066\n",
      "77/77 [==============================] - 30s 392ms/step - loss: 0.4546 - accuracy: 0.8048 - val_loss: 0.4858 - val_accuracy: 0.7951\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.3939 - accuracy: 0.8163\n",
      "Epoch 12: val_loss improved from 0.47066 to 0.39844, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 31s 397ms/step - loss: 0.3939 - accuracy: 0.8163 - val_loss: 0.3984 - val_accuracy: 0.8459\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.8307\n",
      "Epoch 13: val_loss did not improve from 0.39844\n",
      "77/77 [==============================] - 30s 392ms/step - loss: 0.3395 - accuracy: 0.8307 - val_loss: 0.4224 - val_accuracy: 0.8295\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.8475\n",
      "Epoch 14: val_loss improved from 0.39844 to 0.35500, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 31s 406ms/step - loss: 0.2976 - accuracy: 0.8475 - val_loss: 0.3550 - val_accuracy: 0.8508\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.2899 - accuracy: 0.8520\n",
      "Epoch 15: val_loss did not improve from 0.35500\n",
      "77/77 [==============================] - 31s 401ms/step - loss: 0.2899 - accuracy: 0.8520 - val_loss: 0.3560 - val_accuracy: 0.8525\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.8741\n",
      "Epoch 16: val_loss improved from 0.35500 to 0.34287, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 394ms/step - loss: 0.2414 - accuracy: 0.8741 - val_loss: 0.3429 - val_accuracy: 0.8541\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.8836\n",
      "Epoch 17: val_loss did not improve from 0.34287\n",
      "77/77 [==============================] - 30s 393ms/step - loss: 0.2428 - accuracy: 0.8836 - val_loss: 0.4072 - val_accuracy: 0.8574\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9065\n",
      "Epoch 18: val_loss improved from 0.34287 to 0.33624, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 395ms/step - loss: 0.1932 - accuracy: 0.9065 - val_loss: 0.3362 - val_accuracy: 0.8607\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.2041 - accuracy: 0.8975\n",
      "Epoch 19: val_loss improved from 0.33624 to 0.30045, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 395ms/step - loss: 0.2041 - accuracy: 0.8975 - val_loss: 0.3004 - val_accuracy: 0.8820\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.1673 - accuracy: 0.9151\n",
      "Epoch 20: val_loss improved from 0.30045 to 0.27305, saving model to array_model.hdf5\n",
      "77/77 [==============================] - 30s 396ms/step - loss: 0.1673 - accuracy: 0.9151 - val_loss: 0.2731 - val_accuracy: 0.9016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17743cd5790>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test), callbacks=[monitor, checkpointer], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 2s 75ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.47039347e-04, 9.99391437e-01, 4.61595017e-04],\n",
       "       [8.68321717e-01, 9.95130837e-02, 3.21651697e-02],\n",
       "       [1.42810680e-03, 9.57365751e-01, 4.12061922e-02],\n",
       "       ...,\n",
       "       [1.17672855e-04, 9.99578059e-01, 3.04185669e-04],\n",
       "       [6.33158535e-03, 9.85928953e-01, 7.73942005e-03],\n",
       "       [4.55464376e-03, 3.31174291e-04, 9.95114207e-01]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79       137\n",
      "           1       0.87      0.94      0.91       278\n",
      "           2       0.98      0.96      0.97       195\n",
      "\n",
      "    accuracy                           0.90       610\n",
      "   macro avg       0.90      0.88      0.89       610\n",
      "weighted avg       0.90      0.90      0.90       610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "print(classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b916bdd1a3812159cb85ae0f0ca445e7439c7ef725ff4a71e29143f85709ad62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
